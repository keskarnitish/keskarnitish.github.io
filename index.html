<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Nitish Shirish Keskar</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-109844248-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<div id="layout-content">
<div id="toptitle">
<h1>Nitish Shirish Keskar</h1>
</div>
<table class="imgtable"><tr><td>
<img src="nitishkeskar_portrait.jpg" alt="Portrait of Nitish Keskar" width="200px" height="200px" />&nbsp;</td>
<td align="left"><p>I'm a researcher at <a href="http://www.openai.com">OpenAI</a> where I work on large language models. Previously, I was a Principal Research Scientist at <a href="https://einstein.ai/">Salesforce Research</a> in Palo Alto where I worked on both research and applications of Deep Learning and Natural Language Processing techniques.</p>
<p>I received my PhD from <a href="http://www.northwestern.edu/">Northwestern University</a> in 2017 under the supervision of <a href="http://users.iems.northwestern.edu/~nocedal/">Prof. Jorge Nocedal</a> and <a href="http://users.iems.northwestern.edu/~andreasw/">Prof. Andreas Waechter</a>. For my PhD, I focused on efficiently finding solutions to Mathematical Optimization problems which are nonsmooth or stochastic. This includes several problems in Machine Learning and Deep Learning. </p>
</td></tr></table>
<p><hr></p>
<p>Over the years, I have been fortunate to be able to work on a broad set of topics such as:</p>
<ul>
<li><p>Language Modeling (<a href="https://arxiv.org/abs/1708.02182">AWD-LSTM</a>, <a href="https://arxiv.org/abs/1909.05858">CTRL</a>, <a href="https://arxiv.org/abs/2009.06367">GeDi</a>)</p>
</li>
<li><p>Multitask Learning (<a href="https://arxiv.org/abs/1806.08730">decaNLP</a>)</p>
</li>
<li><p>Machine Translation (<a href="https://arxiv.org/abs/1711.02132">Weighted Transformer</a>)</p>
</li>
<li><p>Paraphrasing (<a href="https://arxiv.org/abs/2010.12885">Unsupervised Paraphrasing</a>)</p>
</li>
<li><p>Subword Tokenization (<a href="https://arxiv.org/abs/2010.12730">Char2Subword</a>)</p>
</li>
<li><p>Model Security (<a href="https://aclanthology.org/2020.emnlp-main.501/">Multilingual Stealing</a>)</p>
</li>
<li><p>Extending Transformer Language Models to Protein Generation (<a href="https://arxiv.org/abs/2004.03497">ProGen</a>)</p>
</li>
<li><p>Generalization and Deep Learning (<a href="https://openreview.net/forum?id=H1oyRlYgg">Large Batch Training and Sharp Minima</a>, <a href="http://proceedings.mlr.press/v108/wang20f.html">PAC-Bayes Approach</a>, <a href="https://arxiv.org/abs/1910.10245">Path Sampling</a>)</p>
</li>
<li><p>Mathematical Optimization (<a href="https://arxiv.org/abs/1712.07628">Hybrid SGD-Adam Optimizer</a>, <a href="https://www.tandfonline.com/doi/full/10.1080/10556788.2016.1138222">L1-norm Minimization</a>, <a href="https://www.tandfonline.com/doi/abs/10.1080/10556788.2017.1378652?journalCode=goms20">Nonsmooth L-BFGS</a>, <a href="https://ieeexplore.ieee.org/abstract/document/7178917">Nonmonotone SGD</a>, <a href="https://link.springer.com/chapter/10.1007/978-3-319-46128-1_1">adaQN</a>)</p>
</li>
<li><p>Medical AI (<a href="https://www.nature.com/articles/s41467-020-19334-3">Breast Cancer Detection</a>)</p>
</li>
</ul>
<p>My <a href="https://scholar.google.com/citations?user=CJ-_cEEAAAAJ&amp;hl=en">Google Scholar</a> contains a list of all my publications. </p>
<p>I am also interested in machine learning systems and tooling. I have also authored an engineering blog on <a href="https://blog.einstein.ai/benchmarking-tensorrt-inference-server/">efficient serving of BERT-like models</a>. </p>
<h2>Contact</h2>
<p>Email: <a href="mailto:keskar.nitish@gmail.com">keskar.nitish@gmail.com</a> <br /></p>
<h2>Links</h2>
<ul>
<li><p><a href="https://scholar.google.com/citations?user=CJ-_cEEAAAAJ&amp;hl=en">Google Scholar</a></p>
</li>
<li><p><a href="https://semanticscholar.org/author/Nitish-Shirish-Keskar/2924281">Semantic Scholar</a></p>
</li>
<li><p><a href="https://www.linkedin.com/in/nitishkeskar">LinkedIn</a></p>
</li>
<li><p><a href="https://www.twitter.com/strongduality">Twitter</a></p>
</li>
<li><p><a href="https://www.github.com/keskarnitish">GitHub</a></p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2022-06-04 20:01:59 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</div>
</body>
</html>
